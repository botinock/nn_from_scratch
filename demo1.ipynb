{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "df_train = pd.read_csv('data_le.txt', sep=r\"\\s+\", header=None, names=['x1', 'x2', 'y'])\n",
    "df_test = pd.read_csv('data_cc1.txt', sep=r\"\\s+\", header=None, names=['x1', 'x2', 'y'])\n",
    "\n",
    "df_train['y'] = (df_train['y'] + 1) / 2\n",
    "df_test['y'] = (df_test['y'] + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.dataset import DataSet\n",
    "from nn.model import Sequential\n",
    "from nn.linear import Linear\n",
    "from nn.activation import Sigmoid\n",
    "from nn.loss import BCE\n",
    "from nn.optimizer import SGD\n",
    "from nn.weights import xavier_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(df_train[['x1', 'x2']].values, df_train['y'].values)\n",
    "test_dataset = DataSet(df_test[['x1', 'x2']].values, df_test['y'].values, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as sk_metrics\n",
    "\n",
    "def calculate_metrics(pred, target, thresh=0.5):\n",
    "    metrics = {}\n",
    "    metrics['ap'] = sk_metrics.average_precision_score(target, pred)\n",
    "    try:\n",
    "        metrics['auc'] = sk_metrics.roc_auc_score(target, pred)\n",
    "    except:\n",
    "        metrics['auc'] = metrics['ap']\n",
    "    metrics['acc'] = sk_metrics.accuracy_score(target, pred > thresh)\n",
    "    metrics['p'] = sk_metrics.precision_score(target, pred > thresh)\n",
    "    metrics['r'] = sk_metrics.recall_score(target, pred > thresh)\n",
    "    metrics['f1'] = sk_metrics.f1_score(target, pred > thresh)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'epoches': 100,\n",
    "    'lr': 1e-1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    layers=[       \n",
    "        Linear(2, 1, weights_init=xavier_normal),\n",
    "        Sigmoid()\n",
    "    ],\n",
    "    opt=SGD(lr=params['lr']))\n",
    "loss_fn = BCE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 / Train: : 32batches [00:00, 133.88batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0169, p=0.998, r=1]\n",
      "Epoch 0 / Test: : 1batch [00:00, 125.00batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.016, p=1, r=1]\n",
      "Epoch 1 / Train: : 32batches [00:00, 199.99batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.017, p=1, r=0.998] \n",
      "Epoch 1 / Test: : 1batch [00:00, 166.47batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.016, p=1, r=1]\n",
      "Epoch 2 / Train: : 32batches [00:00, 192.16batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0169, p=0.998, r=1]\n",
      "Epoch 2 / Test: : 1batch [00:00, 142.90batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0162, p=1, r=1]\n",
      "Epoch 3 / Train: : 32batches [00:00, 213.31batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0169, p=0.998, r=0.998]\n",
      "Epoch 3 / Test: : 1batch [00:00, 143.05batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.016, p=1, r=1]\n",
      "Epoch 4 / Train: : 32batches [00:00, 206.45batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0169, p=0.998, r=0.998]\n",
      "Epoch 4 / Test: : 1batch [00:00, 166.76batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0159, p=1, r=1]\n",
      "Epoch 5 / Train: : 32batches [00:00, 207.80batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0168, p=1, r=1]\n",
      "Epoch 5 / Test: : 1batch [00:00, 142.89batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0159, p=1, r=1]\n",
      "Epoch 6 / Train: : 32batches [00:00, 202.53batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0167, p=1, r=1]\n",
      "Epoch 6 / Test: : 1batch [00:00, 125.09batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0161, p=1, r=1]\n",
      "Epoch 7 / Train: : 32batches [00:00, 193.33batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0168, p=0.998, r=0.998]\n",
      "Epoch 7 / Test: : 1batch [00:00, 143.03batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0159, p=1, r=1]\n",
      "Epoch 8 / Train: : 32batches [00:00, 203.81batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0167, p=1, r=1]\n",
      "Epoch 8 / Test: : 1batch [00:00, 166.43batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0161, p=1, r=1]\n",
      "Epoch 9 / Train: : 32batches [00:00, 206.43batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0168, p=0.998, r=0.998]\n",
      "Epoch 9 / Test: : 1batch [00:00, 143.14batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0162, p=1, r=1]\n",
      "Epoch 10 / Train: : 32batches [00:00, 212.61batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0166, p=0.997, r=1]\n",
      "Epoch 10 / Test: : 1batch [00:00, 166.69batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0163, p=1, r=1]\n",
      "Epoch 11 / Train: : 32batches [00:00, 210.55batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0167, p=0.998, r=0.998]\n",
      "Epoch 11 / Test: : 1batch [00:00, 166.73batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0159, p=1, r=1]\n",
      "Epoch 12 / Train: : 32batches [00:00, 195.12batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0167, p=0.998, r=1]\n",
      "Epoch 12 / Test: : 1batch [00:00, 143.02batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0159, p=1, r=1]\n",
      "Epoch 13 / Train: : 32batches [00:00, 197.64batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0167, p=0.998, r=0.998]\n",
      "Epoch 13 / Test: : 1batch [00:00, 142.75batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0158, p=1, r=1]\n",
      "Epoch 14 / Train: : 32batches [00:00, 210.52batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0166, p=1, r=0.998]\n",
      "Epoch 14 / Test: : 1batch [00:00, 143.01batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0159, p=1, r=1]\n",
      "Epoch 15 / Train: : 32batches [00:00, 171.10batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0166, p=0.999, r=0.998]\n",
      "Epoch 15 / Test: : 1batch [00:00, 125.19batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0157, p=1, r=1]\n",
      "Epoch 16 / Train: : 32batches [00:00, 173.91batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0166, p=0.998, r=0.998]\n",
      "Epoch 16 / Test: : 1batch [00:00, 142.92batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0157, p=1, r=1]\n",
      "Epoch 17 / Train: : 32batches [00:00, 170.21batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0165, p=0.998, r=1]\n",
      "Epoch 17 / Test: : 1batch [00:00, 124.51batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0157, p=1, r=1]\n",
      "Epoch 18 / Train: : 32batches [00:00, 165.80batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0165, p=1, r=1]\n",
      "Epoch 18 / Test: : 1batch [00:00, 166.82batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.016, p=1, r=1]\n",
      "Epoch 19 / Train: : 32batches [00:00, 207.77batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0165, p=0.998, r=0.998]\n",
      "Epoch 19 / Test: : 1batch [00:00, 125.03batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0158, p=1, r=1]\n",
      "Epoch 20 / Train: : 32batches [00:00, 197.55batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0164, p=1, r=0.998]\n",
      "Epoch 20 / Test: : 1batch [00:00, 142.93batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0162, p=1, r=1]\n",
      "Epoch 21 / Train: : 32batches [00:00, 206.46batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0165, p=0.998, r=0.998]\n",
      "Epoch 21 / Test: : 1batch [00:00, 143.15batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0156, p=1, r=1]\n",
      "Epoch 22 / Train: : 32batches [00:00, 206.40batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0164, p=0.998, r=0.998]\n",
      "Epoch 22 / Test: : 1batch [00:00, 166.84batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0155, p=1, r=1]\n",
      "Epoch 23 / Train: : 32batches [00:00, 226.91batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0164, p=1, r=1]\n",
      "Epoch 23 / Test: : 1batch [00:00, 200.08batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0157, p=1, r=1]\n",
      "Epoch 24 / Train: : 32batches [00:00, 187.14batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0163, p=0.998, r=0.998]\n",
      "Epoch 24 / Test: : 1batch [00:00, 111.12batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0158, p=1, r=1]\n",
      "Epoch 25 / Train: : 32batches [00:00, 216.22batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0163, p=0.998, r=1]\n",
      "Epoch 25 / Test: : 1batch [00:00, 166.61batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0159, p=1, r=1]\n",
      "Epoch 26 / Train: : 32batches [00:00, 220.68batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0164, p=0.998, r=0.998]\n",
      "Epoch 26 / Test: : 1batch [00:00, 166.79batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0156, p=1, r=1]\n",
      "Epoch 27 / Train: : 32batches [00:00, 216.20batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0163, p=1, r=0.998]\n",
      "Epoch 27 / Test: : 1batch [00:00, 166.82batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0158, p=1, r=1]\n",
      "Epoch 28 / Train: : 32batches [00:00, 219.15batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0163, p=0.998, r=0.998]\n",
      "Epoch 28 / Test: : 1batch [00:00, 166.70batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0155, p=1, r=1]\n",
      "Epoch 29 / Train: : 32batches [00:00, 222.23batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0162, p=0.998, r=1]\n",
      "Epoch 29 / Test: : 1batch [00:00, 125.00batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0158, p=1, r=1]\n",
      "Epoch 30 / Train: : 32batches [00:00, 210.53batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0162, p=0.998, r=0.998]\n",
      "Epoch 30 / Test: : 1batch [00:00, 166.67batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0156, p=1, r=1]\n",
      "Epoch 31 / Train: : 32batches [00:00, 189.35batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0162, p=0.998, r=0.998]\n",
      "Epoch 31 / Test: : 1batch [00:00, 200.18batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0155, p=1, r=1]\n",
      "Epoch 32 / Train: : 32batches [00:00, 219.15batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0162, p=1, r=1]\n",
      "Epoch 32 / Test: : 1batch [00:00, 166.72batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0158, p=1, r=1]\n",
      "Epoch 33 / Train: : 32batches [00:00, 216.17batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0162, p=0.998, r=0.998]\n",
      "Epoch 33 / Test: : 1batch [00:00, 99.95batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.016, p=1, r=1]\n",
      "Epoch 34 / Train: : 32batches [00:00, 222.22batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0161, p=1, r=0.998]\n",
      "Epoch 34 / Test: : 1batch [00:00, 142.96batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0154, p=1, r=1]\n",
      "Epoch 35 / Train: : 32batches [00:00, 189.35batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0161, p=1, r=1]\n",
      "Epoch 35 / Test: : 1batch [00:00, 166.67batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0154, p=1, r=1]\n",
      "Epoch 36 / Train: : 32batches [00:00, 206.46batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0162, p=0.998, r=0.998]\n",
      "Epoch 36 / Test: : 1batch [00:00, 166.75batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0154, p=1, r=1]\n",
      "Epoch 37 / Train: : 32batches [00:00, 216.21batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0162, p=0.998, r=1]\n",
      "Epoch 37 / Test: : 1batch [00:00, 166.69batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 38 / Train: : 32batches [00:00, 225.33batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.016, p=1, r=1] \n",
      "Epoch 38 / Test: : 1batch [00:00, 166.79batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0155, p=1, r=1]\n",
      "Epoch 39 / Train: : 32batches [00:00, 209.16batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.016, p=0.997, r=0.998] \n",
      "Epoch 39 / Test: : 1batch [00:00, 142.89batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 40 / Train: : 32batches [00:00, 225.35batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.016, p=1, r=0.998]\n",
      "Epoch 40 / Test: : 1batch [00:00, 142.87batch/s, acc=0.997, ap=1, auc=1, f1=0.997, loss=0.0151, p=1, r=0.993]\n",
      "Epoch 41 / Train: : 32batches [00:00, 222.22batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0161, p=1, r=1]\n",
      "Epoch 41 / Test: : 1batch [00:00, 142.96batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0152, p=1, r=1]\n",
      "Epoch 42 / Train: : 32batches [00:00, 222.23batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.016, p=1, r=1] \n",
      "Epoch 42 / Test: : 1batch [00:00, 142.89batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0156, p=1, r=1]\n",
      "Epoch 43 / Train: : 32batches [00:00, 216.16batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.016, p=1, r=0.998] \n",
      "Epoch 43 / Test: : 1batch [00:00, 166.67batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0155, p=1, r=1]\n",
      "Epoch 44 / Train: : 32batches [00:00, 217.68batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0159, p=0.998, r=1]\n",
      "Epoch 44 / Test: : 1batch [00:00, 142.69batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 45 / Train: : 32batches [00:00, 201.27batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0159, p=1, r=1]\n",
      "Epoch 45 / Test: : 1batch [00:00, 124.86batch/s, acc=0.993, ap=1, auc=1, f1=0.994, loss=0.0161, p=0.987, r=1]\n",
      "Epoch 46 / Train: : 32batches [00:00, 213.33batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0159, p=0.998, r=1]\n",
      "Epoch 46 / Test: : 1batch [00:00, 166.90batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0158, p=1, r=1]\n",
      "Epoch 47 / Train: : 32batches [00:00, 211.92batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0159, p=0.998, r=1]\n",
      "Epoch 47 / Test: : 1batch [00:00, 125.22batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0156, p=1, r=1]\n",
      "Epoch 48 / Train: : 32batches [00:00, 207.79batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0158, p=0.998, r=0.998]\n",
      "Epoch 48 / Test: : 1batch [00:00, 166.32batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0152, p=1, r=1]\n",
      "Epoch 49 / Train: : 32batches [00:00, 222.23batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0159, p=1, r=1]\n",
      "Epoch 49 / Test: : 1batch [00:00, 142.96batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 50 / Train: : 32batches [00:00, 219.18batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0158, p=0.998, r=1]\n",
      "Epoch 50 / Test: : 1batch [00:00, 166.75batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 51 / Train: : 32batches [00:00, 225.36batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0158, p=0.998, r=0.998]\n",
      "Epoch 51 / Test: : 1batch [00:00, 166.86batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 52 / Train: : 32batches [00:00, 210.53batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0157, p=0.998, r=0.998]\n",
      "Epoch 52 / Test: : 1batch [00:00, 143.08batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0155, p=1, r=1]\n",
      "Epoch 53 / Train: : 32batches [00:00, 217.67batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0159, p=0.998, r=0.998]\n",
      "Epoch 53 / Test: : 1batch [00:00, 166.94batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0154, p=1, r=1]\n",
      "Epoch 54 / Train: : 32batches [00:00, 220.70batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0157, p=0.998, r=0.999]\n",
      "Epoch 54 / Test: : 1batch [00:00, 142.85batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0152, p=1, r=1]\n",
      "Epoch 55 / Train: : 32batches [00:00, 196.31batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0158, p=0.998, r=0.998]\n",
      "Epoch 55 / Test: : 1batch [00:00, 167.02batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 56 / Train: : 32batches [00:00, 216.22batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0158, p=0.998, r=0.998]\n",
      "Epoch 56 / Test: : 1batch [00:00, 143.13batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 57 / Train: : 32batches [00:00, 216.21batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0157, p=0.998, r=0.998]\n",
      "Epoch 57 / Test: : 1batch [00:00, 200.06batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0148, p=1, r=1]\n",
      "Epoch 58 / Train: : 32batches [00:00, 211.89batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0157, p=1, r=1]\n",
      "Epoch 58 / Test: : 1batch [00:00, 166.62batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.015, p=1, r=1]\n",
      "Epoch 59 / Train: : 32batches [00:00, 203.81batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0158, p=0.998, r=0.998]\n",
      "Epoch 59 / Test: : 1batch [00:00, 166.51batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0152, p=1, r=1]\n",
      "Epoch 60 / Train: : 32batches [00:00, 222.24batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0157, p=1, r=0.998]\n",
      "Epoch 60 / Test: : 1batch [00:00, 166.66batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 61 / Train: : 32batches [00:00, 217.68batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0157, p=0.998, r=0.998]\n",
      "Epoch 61 / Test: : 1batch [00:00, 166.73batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 62 / Train: : 32batches [00:00, 226.95batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0156, p=1, r=1]\n",
      "Epoch 62 / Test: : 1batch [00:00, 142.92batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0154, p=1, r=1]\n",
      "Epoch 63 / Train: : 32batches [00:00, 223.75batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0156, p=0.998, r=0.998]\n",
      "Epoch 63 / Test: : 1batch [00:00, 166.75batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 64 / Train: : 32batches [00:00, 209.13batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0156, p=1, r=0.998]\n",
      "Epoch 64 / Test: : 1batch [00:00, 167.04batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 65 / Train: : 32batches [00:00, 200.00batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0156, p=1, r=1]\n",
      "Epoch 65 / Test: : 1batch [00:00, 166.97batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n",
      "Epoch 66 / Train: : 32batches [00:00, 225.35batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0155, p=1, r=1]\n",
      "Epoch 66 / Test: : 1batch [00:00, 166.76batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 67 / Train: : 32batches [00:00, 230.22batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0155, p=0.998, r=0.997]\n",
      "Epoch 67 / Test: : 1batch [00:00, 166.67batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 68 / Train: : 32batches [00:00, 206.37batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0154, p=0.998, r=0.999]\n",
      "Epoch 68 / Test: : 1batch [00:00, 166.81batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.015, p=1, r=1]\n",
      "Epoch 69 / Train: : 32batches [00:00, 228.57batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0155, p=1, r=0.998]\n",
      "Epoch 69 / Test: : 1batch [00:00, 166.84batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 70 / Train: : 32batches [00:00, 216.21batches/s, acc=0.998, ap=1, auc=1, f1=0.997, loss=0.0153, p=0.998, r=0.997]\n",
      "Epoch 70 / Test: : 1batch [00:00, 142.78batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0148, p=1, r=1]\n",
      "Epoch 71 / Train: : 32batches [00:00, 219.19batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0156, p=0.998, r=0.998]\n",
      "Epoch 71 / Test: : 1batch [00:00, 166.61batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0148, p=1, r=1]\n",
      "Epoch 72 / Train: : 32batches [00:00, 216.22batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0154, p=1, r=1]\n",
      "Epoch 72 / Test: : 1batch [00:00, 166.59batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n",
      "Epoch 73 / Train: : 32batches [00:00, 209.07batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0154, p=0.998, r=0.998]\n",
      "Epoch 73 / Test: : 1batch [00:00, 142.91batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.015, p=1, r=1]\n",
      "Epoch 74 / Train: : 32batches [00:00, 210.53batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0154, p=0.998, r=0.997]\n",
      "Epoch 74 / Test: : 1batch [00:00, 111.18batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0152, p=1, r=1]\n",
      "Epoch 75 / Train: : 32batches [00:00, 196.30batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0154, p=0.998, r=0.998]\n",
      "Epoch 75 / Test: : 1batch [00:00, 166.57batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 76 / Train: : 32batches [00:00, 219.21batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0154, p=0.998, r=1]\n",
      "Epoch 76 / Test: : 1batch [00:00, 166.73batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.015, p=1, r=1]\n",
      "Epoch 77 / Train: : 32batches [00:00, 220.70batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0154, p=1, r=0.998]\n",
      "Epoch 77 / Test: : 1batch [00:00, 166.80batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 78 / Train: : 32batches [00:00, 178.41batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0154, p=0.998, r=1]\n",
      "Epoch 78 / Test: : 1batch [00:00, 143.09batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n",
      "Epoch 79 / Train: : 32batches [00:00, 184.97batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0154, p=0.998, r=0.998]\n",
      "Epoch 79 / Test: : 1batch [00:00, 166.74batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0148, p=1, r=1]\n",
      "Epoch 80 / Train: : 32batches [00:00, 214.74batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0153, p=0.998, r=0.998]\n",
      "Epoch 80 / Test: : 1batch [00:00, 166.93batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n",
      "Epoch 81 / Train: : 32batches [00:00, 226.12batches/s, acc=0.998, ap=1, auc=1, f1=0.997, loss=0.0153, p=0.996, r=0.998]\n",
      "Epoch 81 / Test: : 1batch [00:00, 199.84batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0148, p=1, r=1]\n",
      "Epoch 82 / Train: : 32batches [00:00, 223.78batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0153, p=0.998, r=1]\n",
      "Epoch 82 / Test: : 1batch [00:00, 142.88batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.015, p=1, r=1]\n",
      "Epoch 83 / Train: : 32batches [00:00, 216.21batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0152, p=1, r=0.998]\n",
      "Epoch 83 / Test: : 1batch [00:00, 166.82batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0148, p=1, r=1]\n",
      "Epoch 84 / Train: : 32batches [00:00, 205.12batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0152, p=0.998, r=0.998]\n",
      "Epoch 84 / Test: : 1batch [00:00, 142.94batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0147, p=1, r=1]\n",
      "Epoch 85 / Train: : 32batches [00:00, 216.18batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0153, p=1, r=1]\n",
      "Epoch 85 / Test: : 1batch [00:00, 200.13batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0146, p=1, r=1]\n",
      "Epoch 86 / Train: : 32batches [00:00, 203.81batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0152, p=0.998, r=1]\n",
      "Epoch 86 / Test: : 1batch [00:00, 166.86batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0144, p=1, r=1]\n",
      "Epoch 87 / Train: : 32batches [00:00, 193.94batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0152, p=1, r=1]\n",
      "Epoch 87 / Test: : 1batch [00:00, 166.63batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0146, p=1, r=1]\n",
      "Epoch 88 / Train: : 32batches [00:00, 213.34batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 88 / Test: : 1batch [00:00, 166.63batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n",
      "Epoch 89 / Train: : 32batches [00:00, 219.18batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0151, p=0.998, r=0.998]\n",
      "Epoch 89 / Test: : 1batch [00:00, 166.73batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n",
      "Epoch 90 / Train: : 32batches [00:00, 217.69batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0152, p=0.998, r=0.998]\n",
      "Epoch 90 / Test: : 1batch [00:00, 166.62batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n",
      "Epoch 91 / Train: : 32batches [00:00, 214.77batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0151, p=0.998, r=0.998]\n",
      "Epoch 91 / Test: : 1batch [00:00, 143.02batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0148, p=1, r=1]\n",
      "Epoch 92 / Train: : 32batches [00:00, 217.69batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.0151, p=0.998, r=1]\n",
      "Epoch 92 / Test: : 1batch [00:00, 142.93batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n",
      "Epoch 93 / Train: : 32batches [00:00, 220.69batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.0152, p=0.998, r=0.998]\n",
      "Epoch 93 / Test: : 1batch [00:00, 166.82batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0148, p=1, r=1]\n",
      "Epoch 94 / Train: : 32batches [00:00, 225.36batches/s, acc=0.999, ap=1, auc=1, f1=0.999, loss=0.015, p=0.998, r=1] \n",
      "Epoch 94 / Test: : 1batch [00:00, 142.95batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n",
      "Epoch 95 / Train: : 32batches [00:00, 223.75batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.015, p=0.998, r=0.998] \n",
      "Epoch 95 / Test: : 1batch [00:00, 124.94batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0146, p=1, r=1]\n",
      "Epoch 96 / Train: : 32batches [00:00, 170.21batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.0151, p=1, r=1]\n",
      "Epoch 96 / Test: : 1batch [00:00, 166.63batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0147, p=1, r=1]\n",
      "Epoch 97 / Train: : 32batches [00:00, 213.34batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.015, p=1, r=1] \n",
      "Epoch 97 / Test: : 1batch [00:00, 166.87batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0148, p=1, r=1]\n",
      "Epoch 98 / Train: : 32batches [00:00, 216.21batches/s, acc=0.998, ap=1, auc=1, f1=0.998, loss=0.015, p=0.998, r=0.998] \n",
      "Epoch 98 / Test: : 1batch [00:00, 166.82batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0147, p=1, r=1]\n",
      "Epoch 99 / Train: : 32batches [00:00, 220.69batches/s, acc=1, ap=1, auc=1, f1=1, loss=0.015, p=1, r=1] \n",
      "Epoch 99 / Test: : 1batch [00:00, 142.98batch/s, acc=1, ap=1, auc=1, f1=1, loss=0.0149, p=1, r=1]\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"test\"\n",
    "i = 1\n",
    "fold = f'demo_1'\n",
    "folder = f'./{fold}/{exp_name}'\n",
    "while os.path.isdir(folder):\n",
    "    i += 1\n",
    "    folder = f'./{fold}/{exp_name}_{i}'\n",
    "writer = SummaryWriter(folder)\n",
    "\n",
    "for epoch in range(params['epoches']):\n",
    "    # Train\n",
    "    with tqdm.tqdm(train_dataset, unit=\"batches\") as tepoch:\n",
    "        epoch_metrics = {}\n",
    "        counter = 0\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch} / Train\")\n",
    "            \n",
    "            output = model(data).squeeze()\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            # Metrics\n",
    "            metrics = calculate_metrics(output, target)\n",
    "            metrics['loss'] = loss\n",
    "\n",
    "            # Tensorboard\n",
    "            cur_batch = len(target)\n",
    "            if counter:\n",
    "                for k, v in metrics.items():\n",
    "                    epoch_metrics[k] = (epoch_metrics[k]*counter + v*cur_batch)/(counter + cur_batch)\n",
    "            else:\n",
    "                epoch_metrics = metrics.copy()\n",
    "            counter += cur_batch\n",
    "\n",
    "            # Backward\n",
    "            model.backward(loss_fn.backward())\n",
    "\n",
    "            tepoch.set_postfix(**epoch_metrics)\n",
    "        for k, v in epoch_metrics.items():\n",
    "            writer.add_scalar(f\"Train/{k}\", v, global_step=epoch)\n",
    "\n",
    "    # Test\n",
    "    with tqdm.tqdm(test_dataset, unit=\"batch\") as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch} / Test\")\n",
    "            \n",
    "            output = model(data).squeeze()\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            # Metrics\n",
    "            metrics = calculate_metrics(output, target)\n",
    "            metrics['loss'] = loss\n",
    "\n",
    "            # Tensorboard\n",
    "            for k, v in metrics.items():\n",
    "                writer.add_scalar(f\"Test/{k}\", v, global_step=epoch)\n",
    "\n",
    "            tepoch.set_postfix(**metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef47a6bd00e2ad3621fb1fa928a4550ea9d693bd1a9d64d82e8b39edfca4292c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('coursach_rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
